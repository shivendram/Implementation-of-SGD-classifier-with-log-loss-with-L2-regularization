{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 10 epochs took 0.10 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)  # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    a = np.arange(len(dim))\n",
    "    w = np.zeros_like(a)\n",
    "    b = 0\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0]\n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "    assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "    return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    return 1/(1+math.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val=sigmoid(z)\n",
    "    assert(val==0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    loss = 0 \n",
    "    for y_tr,y_pr in zip(y_true,y_pred):\n",
    "        loss += (((y_tr)*np.log10(y_pr)) + ((1-y_tr)*np.log10(1-y_pr)))*(-1/len(y_true)) \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw = x*(y - sigmoid(np.dot(w.T, x) + b)) - ((alpha)*(1/N) * w)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03932417, -1.65802126,  0.39552179,  1.93522773,  0.57391643,\n",
       "        1.40717219,  0.43385535,  0.02036643, -0.42413939, -0.99725862,\n",
       "       -1.83576236, -0.00725938, -1.00531444, -0.03686952,  2.77293046])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "gradient_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_db(x,y,w,b):\n",
    "    r = y - sigmoid(np.dot(w.T,x) + b)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "    grad_db=gradient_db(x,y,w,b)\n",
    "    #print(grad_b)\n",
    "    assert(grad_db==-0.5)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    N = len(X_train)\n",
    "    \n",
    "     # for every epoch\n",
    "    for epoch in range(1,epochs+1):\n",
    "        \n",
    "       # for every data point(X_train,y_train) \n",
    "        for i in range(len(X_train)):\n",
    "            \n",
    "            #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "            dw = gradient_dw(X_train[i],y_train[i],w,b,alpha,N) \n",
    "            \n",
    "            #compute gradient w.r.to b (call the gradient_db() function)\n",
    "            db = gradient_db(X_train[i],y_train[i],w,b)\n",
    "            \n",
    "            #update w, b\n",
    "            w = w + eta0 * dw\n",
    "            b = b + eta0 * db\n",
    "         \n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        y_train_pred = []\n",
    "        for x in X_train:\n",
    "            train_op = sigmoid(np.dot(w.T,x) + b)\n",
    "            \n",
    "            # store all the train loss values in a list\n",
    "            y_train_pred.append(train_op)\n",
    "        \n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        loss_train = logloss(y_train,y_train_pred)\n",
    "        train_loss.append(loss_train)\n",
    "        \n",
    "        #predict the output of x_test[for all data points in X_test] using w,b\n",
    "        y_test_pred = []\n",
    "        for x in X_test:\n",
    "            test_op = sigmoid(np.dot(w.T,x) + b) \n",
    "            y_test_pred.append(test_op)\n",
    "        \n",
    "         #compute the loss between predicted and actual values (call the loss function)\n",
    "        loss_test = logloss(y_test,y_test_pred)\n",
    "        \n",
    "        # store all the test loss values in a list\n",
    "        test_loss.append(loss_test)\n",
    "        \n",
    "       \n",
    "     # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "        if len(train_loss)>1:\n",
    "            previous_computed_loss = train_loss[-2]\n",
    "            latest_computed_loss = train_loss[-1]\n",
    "            \n",
    "            if previous_computed_loss-latest_computed_loss < abs(0.00001):\n",
    "                return w,b,train_loss,test_loss,epoch \n",
    "            \n",
    "        \n",
    "    return w,b,train_loss,test_loss,epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=50\n",
    "w,b,train_loss,test_loss,epoch =train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.42605234,  0.19187028, -0.1470358 ,  0.33812874, -0.21606161,\n",
       "         0.56732498, -0.44526597, -0.09091644,  0.21964959,  0.1715521 ,\n",
       "         0.19676699,  0.00103546, -0.07935642,  0.33892975,  0.02250835]),\n",
       " -0.8685774198604435,\n",
       " [0.1754574844285458,\n",
       "  0.1686715705033285,\n",
       "  0.16639167992462875,\n",
       "  0.1653682753740306,\n",
       "  0.16485707459547086,\n",
       "  0.16458820012928346,\n",
       "  0.16444271323364415,\n",
       "  0.16436263615827004,\n",
       "  0.16431806946667887,\n",
       "  0.1642930737413257,\n",
       "  0.1642789743093408,\n",
       "  0.1642709854583551],\n",
       " [0.17595474423213822,\n",
       "  0.16939931358951107,\n",
       "  0.16720591194885812,\n",
       "  0.16621717799335012,\n",
       "  0.1657195946397849,\n",
       "  0.16545557095508578,\n",
       "  0.16531135020799534,\n",
       "  0.1652311685317936,\n",
       "  0.16518605898449076,\n",
       "  0.16516045651849845,\n",
       "  0.1651458202870404,\n",
       "  0.16513739835366334],\n",
       " 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b,train_loss,test_loss,epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of sklearn Implementation and Custom Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "         0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "         0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_ # From sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8531383])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_  # From sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00268543 0.61152799 0.27746198 0.76749641 0.21786564 0.98621813\n",
      " 0.02637248 0.33196421 0.63532554 0.6068936  0.62310425 0.4302715\n",
      " 0.34644865 0.76458036 0.44871955]\n"
     ]
    }
   ],
   "source": [
    "# Difference between 'w' of SkLearn Implementation and custom implementation\n",
    "\n",
    "for x,y in zip(w,clf.coef_):\n",
    "    print(abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01543912])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between intercept of SkLearn Implementation and custom implementation\n",
    "\n",
    "abs(clf.intercept_ - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of train loss and test loss vs Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch = list(range(1,epoch+1))\n",
    "\n",
    "plt.plot(Epoch,train_loss,label = 'Train Loss')\n",
    "plt.plot(Epoch,test_loss,label = 'Test Loss')\n",
    "\n",
    "plt.scatter(Epoch,train_loss,label = 'Train Loss Points')\n",
    "plt.scatter(Epoch,test_loss,label = 'Test Loss Points')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epochs vs Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9542933333333333\n",
      "0.95192\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))  # Train Accuracy\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))    # Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
